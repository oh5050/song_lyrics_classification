{"cells":[{"cell_type":"code","execution_count":null,"id":"4493ee0f","metadata":{"id":"4493ee0f"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense"]},{"cell_type":"code","execution_count":null,"id":"c0e130f7","metadata":{"id":"c0e130f7"},"outputs":[],"source":["# 데이터 불러오기\n","train_data = pd.read_csv('텍스트 요약 학습 데이터.csv')\n","test_data = pd.read_csv('가사요약.csv')"]},{"cell_type":"code","execution_count":null,"id":"a3f3ceb6","metadata":{"id":"a3f3ceb6"},"outputs":[],"source":["# 훈련 데이터와 검증 데이터로 나누기\n","train_set, val_set = train_test_split(train_data, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"de2783aa","metadata":{"id":"de2783aa"},"outputs":[],"source":["# 토큰화를 위한 Tokenizer 설정\n","max_words = 10000\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(train_set['가사 전문'])"]},{"cell_type":"code","execution_count":null,"id":"7f2f9280","metadata":{"id":"7f2f9280"},"outputs":[],"source":["# 훈련 데이터와 검증 데이터의 시퀀스 생성\n","train_sequences = tokenizer.texts_to_sequences(train_set['가사 전문'])\n","val_sequences = tokenizer.texts_to_sequences(val_set['가사 전문'])"]},{"cell_type":"code","execution_count":null,"id":"410bc88b","metadata":{"id":"410bc88b"},"outputs":[],"source":["# 시퀀스 패딩\n","max_len = 100  # 패딩 길이\n","train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post', truncating='post')\n","val_padded = pad_sequences(val_sequences, maxlen=max_len, padding='post', truncating='post')"]},{"cell_type":"code","execution_count":null,"id":"cb7b4dc5","metadata":{"id":"cb7b4dc5"},"outputs":[],"source":["# 레이블 데이터 생성\n","train_labels = tokenizer.texts_to_sequences(train_set['가사 요약'])\n","val_labels = tokenizer.texts_to_sequences(val_set['가사 요약'])"]},{"cell_type":"code","execution_count":null,"id":"0ecf9a90","metadata":{"id":"0ecf9a90"},"outputs":[],"source":["# 시퀀스 패딩\n","train_labels_padded = pad_sequences(train_labels, maxlen=max_len, padding='post', truncating='post')\n","val_labels_padded = pad_sequences(val_labels, maxlen=max_len, padding='post', truncating='post')"]},{"cell_type":"code","execution_count":null,"id":"1b7a4eb1","metadata":{"id":"1b7a4eb1"},"outputs":[],"source":["# seq2seq 모델 구성\n","model = Sequential()\n","model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n","model.add(LSTM(128, return_sequences=True))  # Add return_sequences=True for seq2seq\n","model.add(Dense(max_words, activation=None))  # Remove softmax activation"]},{"cell_type":"code","execution_count":null,"id":"b77f4bfa","metadata":{"id":"b77f4bfa"},"outputs":[],"source":["# 모델 컴파일\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"b7035678","metadata":{"id":"b7035678"},"outputs":[],"source":["# 레이블을 원-핫 인코딩\n","from tensorflow.keras.utils import to_categorical\n","train_labels_one_hot = to_categorical(train_labels_padded, num_classes=max_words)\n","val_labels_one_hot = to_categorical(val_labels_padded, num_classes=max_words)"]},{"cell_type":"code","execution_count":null,"id":"41378819","metadata":{"id":"41378819","outputId":"74298bcc-4d85-430c-a8db-f90cef8a7be0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","4/4 [==============================] - 6s 810ms/step - loss: 13.8816 - accuracy: 0.0000e+00 - val_loss: 15.6188 - val_accuracy: 0.0000e+00\n","Epoch 2/10\n","4/4 [==============================] - 2s 524ms/step - loss: 15.5939 - accuracy: 0.0064 - val_loss: 15.5938 - val_accuracy: 0.0045\n","Epoch 3/10\n","4/4 [==============================] - 2s 532ms/step - loss: 15.5635 - accuracy: 0.0313 - val_loss: 15.5707 - val_accuracy: 0.0100\n","Epoch 4/10\n","4/4 [==============================] - 2s 556ms/step - loss: 15.5310 - accuracy: 0.0425 - val_loss: 15.5263 - val_accuracy: 0.0191\n","Epoch 5/10\n","4/4 [==============================] - 2s 526ms/step - loss: 15.5051 - accuracy: 0.0472 - val_loss: 15.1259 - val_accuracy: 0.0318\n","Epoch 6/10\n","4/4 [==============================] - 2s 538ms/step - loss: 15.3695 - accuracy: 0.0512 - val_loss: 15.4737 - val_accuracy: 0.0336\n","Epoch 7/10\n","4/4 [==============================] - 2s 547ms/step - loss: 15.4694 - accuracy: 0.0524 - val_loss: 15.4949 - val_accuracy: 0.0282\n","Epoch 8/10\n","4/4 [==============================] - 2s 511ms/step - loss: 15.4380 - accuracy: 0.0538 - val_loss: 15.4810 - val_accuracy: 0.0318\n","Epoch 9/10\n","4/4 [==============================] - 2s 521ms/step - loss: 15.4231 - accuracy: 0.0576 - val_loss: 15.4298 - val_accuracy: 0.0336\n","Epoch 10/10\n","4/4 [==============================] - 2s 573ms/step - loss: 15.4335 - accuracy: 0.0632 - val_loss: 14.3789 - val_accuracy: 0.0391\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x10adbe19280>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# 모델 훈련\n","model.fit(train_padded, train_labels_one_hot, validation_data=(val_padded, val_labels_one_hot), epochs=10, batch_size=32)"]},{"cell_type":"code","execution_count":null,"id":"025b96ff","metadata":{"id":"025b96ff"},"outputs":[],"source":["# 테스트 데이터 전처리\n","test_sequences = tokenizer.texts_to_sequences(test_data['가사'])\n","test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')"]},{"cell_type":"code","execution_count":null,"id":"389094fb","metadata":{"id":"389094fb","outputId":"b30a3f0c-dafe-4ef9-91d9-c140fe80410e"},"outputs":[{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 1s 77ms/step\n"]}],"source":["# 예측\n","predictions = model.predict(test_padded)"]},{"cell_type":"code","execution_count":null,"id":"eef69b3c","metadata":{"id":"eef69b3c"},"outputs":[],"source":["# 예측 결과 디코딩\n","decoded_predictions = []\n","for prediction in predictions:\n","    decoded_predictions.append(tokenizer.sequences_to_texts([prediction.argmax(axis=-1)])[0])"]},{"cell_type":"code","execution_count":null,"id":"bbd90b32","metadata":{"id":"bbd90b32","outputId":"e01f655d-cecc-48ca-eaf0-1326f4723d59"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                예측 요약\n","0   <OOV> 싶은 싶은 싶은 <OOV> <OOV> <OOV> <OOV> <OOV> <...\n","1   <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV...\n","2   <OOV> <OOV> 싶은 <OOV> 싶은 <OOV> <OOV> <OOV> <OOV...\n","3   싶은 <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <...\n","4   <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV...\n","..                                                ...\n","95  <OOV> <OOV> <OOV> 싶은 <OOV> <OOV> <OOV> <OOV> <...\n","96  싶은 싶은 싶은 싶은 싶은 싶은 싶은 <OOV> <OOV> <OOV> <OOV> 싶...\n","97  싶은 싶은 싶은 <OOV> 싶은 싶은 <OOV> 싶은 싶은 싶은 <OOV> 싶은 싶...\n","98  싶은 마음을 싶은 싶은 싶은 싶은 <OOV> <OOV> <OOV> 싶은 싶은 <OO...\n","99  아름다운 <OOV> <OOV> 싶은 싶은 <OOV> 싶은 싶은 <OOV> 싶은 싶은...\n","\n","[100 rows x 1 columns]\n"]}],"source":["# 결과 출력\n","test_data['예측 요약'] = decoded_predictions\n","print(test_data[['예측 요약']])\n","\n","'''\n","결과에서 보이는 <OOV>는 Out Of Vocabulary(단어 집합에 없는 단어)의 약자.\n","이는 모델이 학습 과정에서 보지 못한 단어나 훈련 시에 포함되지 않은 단어를 나타냄.\n","'''"]},{"cell_type":"code","execution_count":null,"id":"c157e41f","metadata":{"id":"c157e41f"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}